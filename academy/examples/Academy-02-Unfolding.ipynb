{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "from uncertainties import ufloat, correlated_values\n",
    "from uncertainties import unumpy as unp\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import pickle\n",
    "import uncertainties\n",
    "import statsmodels.stats.correlation_tools\n",
    "from uncertainties import covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from analysis_vcb.selection import sig_id_to_label\n",
    "from academy.analysis.plotting import init_plot_style, add_watermark, channel_label\n",
    "from academy.analysis.settings import *\n",
    "from academy.analysis.constants import *\n",
    "\n",
    "init_plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mc = pd.read_hdf('AcademySample.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotoutdir = \"output/Unfolding\"\n",
    "try:\n",
    "    os.makedirs(plotoutdir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [\n",
    "    15,  #S B0 -> D*+ e nu\n",
    "    16,  #S B0 -> D*+ mu nu\n",
    "    #17,  #+ B+ -> D*0 e nu\n",
    "    #18,  #+ B+ -> D*0 mu nu\n",
    "]\n",
    "\n",
    "channels_Dstar = [\n",
    "    #21,  #+ D*0 -> D0 pi0\n",
    "    23,  #S D*+ -> D0 pi+\n",
    "    24,  #S D*+ -> D+ pi0\n",
    "]  \n",
    "channels_D = [\n",
    "    31,  #S D+ -> K- pi+ pi+\n",
    "    32,  #N D+ -> K- pi+ pi+ pi0\n",
    "    33,  #N D+ -> K- pi+ pi+ pi+ pi-\n",
    "    34,  #N D+ -> Ks pi+\n",
    "    35,  #N D+ -> Ks pi+ pi0\n",
    "    36,  #N D+ -> Ks pi+ pi+ pi-\n",
    "    37,  #N D+ -> Ks K^+\n",
    "    38,  #N D+ -> K+ K- pi^+\n",
    "    41,  #S D0 -> K- pi+\n",
    "    42,  #S D0 -> K- pi+ pi0\n",
    "    43,  #S D0 -> K- pi+ pi+ pi-\n",
    "    44,  #N D0 -> K- pi+ pi+ pi- pi0\n",
    "    45,  #N D0 -> Ks pi0\n",
    "    46,  #N D0 -> Ks pi+ pi-\n",
    "    47,  #N D0 -> Ks pi+ pi- pi0\n",
    "    48,  #N D0 -> K+ K+\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_variable = \"m2RecoilSignalSide_after_smearing\" \n",
    "fit_variable_label = r\"$M_\\mathrm{miss}^2$\"\n",
    "fit_variable_unit = r\"GeV$^2$/$c^4$\"\n",
    "fit_bins = np.array([-1.0, -0.25, 0.25, 0.75, 1.25, 2.0])\n",
    "fit_range = (min(fit_bins), max(fit_bins))\n",
    "fit_vois = [\"wReco\", \"costhetalReco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mc = df_mc.query(f\"{fit_range[0]} < {fit_variable} < {fit_range[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = {\n",
    "    15: \"v\",\n",
    "    16: \"s\",   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type=\"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotoutdir = os.path.join(plotoutdir, data_type)\n",
    "try:\n",
    "    os.makedirs(plotoutdir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "print(plotoutdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yields = pd.read_pickle(os.path.join(f\"output/Fitting/data\", \"yields.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = {}\n",
    "for channel in channels:\n",
    "    correlations[channel] = statsmodels.stats.correlation_tools.corr_nearest(  # Fix negative eigenvalues\n",
    "        pd.read_pickle(os.path.join(f\"output/Fitting/{data_type}\", f\"correlation_{channel}.pkl\")).values,\n",
    "        threshold=2e-7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covariances = {}\n",
    "for channel in channels:\n",
    "    covariances[channel] = np.outer(\n",
    "        unp.nominal_values(yields.loc[channel_label[channel], '$\\sigma_\\mathrm{tot}$']), \n",
    "        unp.nominal_values(yields.loc[channel_label[channel], '$\\sigma_\\mathrm{tot}$'])\n",
    "    ) * correlations[channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for channel in channels:\n",
    "    results[channel] = correlated_values(\n",
    "        unp.nominal_values(yields.loc[channel_label[channel], '$\\nu_\\mathrm{sig}$']),\n",
    "        covariances[channel]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from academy.formfactors.BGL import BToDStarBGL\n",
    "from academy.rates.BtoV import BtoV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_bin_boundaries = {}\n",
    "theory_expectation = {}\n",
    "full_theory_bgl = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_central_values = np.array(\n",
    "        [\n",
    "            1.00e-3,  # a0\n",
    "            -2.35e-3,  # a1\n",
    "            0.511e-3,  # b0\n",
    "            0.67e-03,  # b1\n",
    "            3.0e-04,  # c1\n",
    "            -3.68e-03,  # c2\n",
    "        ]\n",
    "    )  # type: np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_Bzero = 5.27963\n",
    "m_Dstarplus = 2.01026\n",
    "\n",
    "vcb_cln = 37.4e-3\n",
    "vcb_bgl = 41.6558e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_Bzero = 5.27963\n",
    "m_Dstarplus = 2.01026\n",
    "\n",
    "vcb_cln = 37.4e-3\n",
    "vcb_bgl = 41.6558e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_bin_boundaries = {}\n",
    "theory_expectation = {}\n",
    "full_theory_bgl = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btodst_bgl_ff = BToDStarBGL(\n",
    "    m_B=m_Bzero,\n",
    "    m_V=m_Dstarplus,\n",
    "    exp_coeff_a = param_central_values[0:2],\n",
    "    exp_coeff_b = param_central_values[2:4],\n",
    "    exp_coeff_c = param_central_values[4:6],\n",
    ")\n",
    "\n",
    "btodst_bgl = BtoV(btodst_bgl_ff, Vcb=vcb_cln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_bin_boundaries[\"mixed\"] = {}\n",
    "for voi in fit_vois:\n",
    "    bin_edges = copy(bin_edges_all[voi])\n",
    "    if voi == \"wReco\":\n",
    "        bin_edges[0]  = btodst_bgl_ff.kinematics.w_range_numerical_stable[0]\n",
    "        bin_edges[-1] = btodst_bgl_ff.kinematics.w_range_numerical_stable[1]\n",
    "        \n",
    "    integration_boundaries = []\n",
    "    for bin_boundaries in zip(bin_edges, bin_edges[1:]):\n",
    "        integration_boundaries.append(bin_boundaries)\n",
    "    theory_bin_boundaries[\"mixed\"][voi] = integration_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reweight total rate, because Vcb is in the rate calculation but we want the BR in the MC\n",
    "total_rate_theory_bgl_weight = (BR_B0_to_Dstplus_lepton.nominal_value / tauBzero) / btodst_bgl.Gamma()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceptance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Acceptance Correction\n",
    "\n",
    "3 a) Use the defined `btodst_bgl` effort class to calculate the expected rate in each bin given the underlying theory model in our MC (BGL, with the defined coefficients above). Nota bene: Divide the expectation by the bin width. Use the defined functions `DGamma_Dw` and `DGamma_DcosL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_expectation[\"mixed\"] = {}\n",
    "theory_expectation[\"mixed\"][\"BGL\"] = {}\n",
    "theory_expectation[\"mixed\"][\"BGL\"][\"wReco\"] = None # Ex. 3a)\n",
    "theory_expectation[\"mixed\"][\"BGL\"][\"costhetalReco\"] = None # Ex. 3a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in channels:\n",
    "    full_theory_bgl[channel] = {}\n",
    "    full_theory_bgl[channel] = np.array([theory_expectation[\"mixed\"][\"BGL\"][voi] for voi in fit_vois]).flatten() * total_rate_theory_bgl_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_theory_bgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyles = {\n",
    "    15: \"-\",\n",
    "    16: \"--\",\n",
    "}\n",
    "\n",
    "acceptance_corrections = {}\n",
    "acceptance_corrections_integrated = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_widths = {}\n",
    "foo = []\n",
    "for voi in fit_vois:\n",
    "    foo.append([x[1] - x[0] for x in theory_bin_boundaries[\"mixed\"][voi]])\n",
    "bin_widths[\"mixed\"] = np.array(foo).flatten()\n",
    "del foo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 b) Calculate the number of signal events, that survive selection and reconstruction. Use the Signal MC for this purpose. \n",
    "\n",
    "The number of expected events in bin $i$ is $n_i = \\sum_j^\\mathrm{events} w_j$, and the uncertainty is $\\sigma_i(n_i) = \\sqrt{\\sum_j^\\mathrm{events} w_j^2}$.\n",
    "\n",
    "The acceptance is then given by the reconstructed number of events over expected number of events (use the defined value in the cell below. Why do we multiply the factors to the rate we calculated in 3a ?)\n",
    "\n",
    "3 c) Why do we multiply the expected rate with 2 * N_BB * BR(B0 --> D* l nu) * tauBzero * bin_width? Explain each factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=130, figsize=(6.4, 4.4))\n",
    "\n",
    "for channel in channels:\n",
    "\n",
    "    histogram = []\n",
    "    histogram_unc = []\n",
    "    for voi in fit_vois:\n",
    "        bin_edges = copy(bin_edges_all[voi])\n",
    "        query = f\"SIG_ID in (4.1, 4.2) and daughter__bo1__cm__spextraInfo__bodecayModeID__bc__bc == {channel} and {fit_range[0]} < {fit_variable} < {fit_range[1]}\"\n",
    "        \n",
    "        # 3 a) Histogram the signal MC (you can query with df_mc.query(query) to select the signal MC. Use np.histogram, remember that we have pre-defined the bin via `bin_edges`, and that the weights are given in the column `__weight_overall__`.\n",
    "    \n",
    "    # Flatten the histogram(_unc) list we defined above.\n",
    "    signal_mc_histogram = np.array(histogram).flatten()\n",
    "    signal_mc_histogram_unc = np.array(histogram_unc).flatten()\n",
    "\n",
    "    \n",
    "    # 3 c) Why do we multiply here with 2 * N_BB * BR(B0 --> D* l nu) * tauBzero * bin_width? Explain each factor\n",
    "    expected = unp.nominal_values(full_theory_bgl[channel] * 2 * N_BB.nominal_value * BR_GENERIC_MIXED.nominal_value * tauBzero * bin_widths[\"mixed\"])\n",
    "    \n",
    "    acceptance_corrections[channel] = unp.uarray(\n",
    "            signal_mc_histogram,\n",
    "            signal_mc_histogram_unc ** 0.5\n",
    "    ) / expected[:20]\n",
    "    acceptance = unp.nominal_values(acceptance_corrections[channel])\n",
    "    acceptance_unc = unp.std_devs(acceptance_corrections[channel])\n",
    "    ax.step(range(-1,21), 1e6*np.array([acceptance[0], *acceptance, acceptance[-1]]), ls=linestyles[channel], where=\"mid\", label=channel_label[channel], lw=1)\n",
    "    ax.bar(\n",
    "        range(0, 20),\n",
    "        height=1e6 * 2 * acceptance_unc,\n",
    "        bottom=1e6 * (acceptance - acceptance_unc),\n",
    "        width=1, alpha=0.3,\n",
    "    )\n",
    "\n",
    "tmp = {}\n",
    "for voi in fit_vois:\n",
    "    tmp[voi] = np.array([(lower, upper) for lower, upper in zip(bin_edges_all[voi], bin_edges_all[voi][1:])])\n",
    "tmp = np.array([b for voi in fit_vois for b in tmp[voi]])\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(tmp)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels([f\"[{lower:.2f}, {upper:.2f}]\" for lower, upper in tmp], rotation=90, fontsize=6)\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "\n",
    "ax.set_xlim(-0.5, 19.5)\n",
    "ax.set_ylim(0, 200)\n",
    "ax.axvline(9.5, color=\"black\")\n",
    "\n",
    "ax.text(0.8, 0.85, \"Normal\\nApproximation\\nIntervals\", fontsize=8, transform=ax.transAxes)\n",
    "ax.text(0.00+0.12, 1.02, r\"$w$\", fontsize=10, transform=ax.transAxes)\n",
    "ax.text(0.55+0.08, 1.02, r\"$\\cos \\theta_\\ell$\", fontsize=10, transform=ax.transAxes)\n",
    "\n",
    "ax.set_ylabel(r\"Acceptance $\\times 10^6$\")\n",
    "ax.legend(frameon=False, fontsize=\"x-small\", ncol=1, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{plotoutdir}/acceptance.pdf\", transparent=True)\n",
    "plt.savefig(f\"{plotoutdir}/acceptance.png\", transparent=True)   \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_pretty(ax, bin_edges_all):\n",
    "    \n",
    "    tmp = {}\n",
    "    for voi in fit_vois:\n",
    "        tmp[voi] = np.array([(lower, upper) for lower, upper in zip(bin_edges_all[voi], bin_edges_all[voi][1:])])\n",
    "    tmp = np.array([b for voi in fit_vois for b in tmp[voi]])\n",
    "    \n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(len(tmp)))\n",
    "    # ... and label them with the respective list entries\n",
    "    ax.set_xticklabels([f\"[{lower:.2f}, {upper:.2f}]\" for lower, upper in tmp], rotation=90, fontsize=6)\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "\n",
    "    ax.set_xlim(-0.5, 19.5)\n",
    "\n",
    "    ax.axvline(9.5, color=\"black\")\n",
    "\n",
    "    ax.text(0.00+0.12, 1.02, r\"$w$\", fontsize=10, transform=ax.transAxes)\n",
    "    ax.text(0.55+0.08, 1.02, r\"$\\cos \\theta_\\ell$\", fontsize=10, transform=ax.transAxes)\n",
    "    \n",
    "    ax.legend(frameon=False, fontsize=\"x-small\", ncol=1, loc='upper left')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Unfolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from academy.analysis.unfolding import extract_bs_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Migration Matrix\n",
    "\n",
    "Next we want to unfold our background subtracted spectrum. For this we want to calculate the migration matrix. Use the pre-defined function below and fill out the function body.\n",
    "The matrix should have the form `w Reco` on the \"x-axis\", and `w MC` on the \"y-axis\". (This can be done differently, but the follow-up code assumes this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_migration_martrix(df, bin_edges, col_mc, col_reco, weight_column=\"__weight_overall__\"):\n",
    "\n",
    "    return None # Ex 4 Return Migration Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_matrices = {}\n",
    "\n",
    "for channel in channels:\n",
    "    migration_matrices[channel] = {}\n",
    "    for voi in fit_vois:\n",
    "        query = f\"SIG_ID in (4.1, 4.2) and {fit_range[0]} < {fit_variable} < {fit_range[1]} and daughter__bo1__cm__spextraInfo__bodecayModeID__bc__bc == {channel}\"\n",
    "        migration_matrices[channel][voi] = determine_migration_martrix(df_mc.query(query), bin_edges_all[voi], voi_mc[voi], voi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_migrations = {}\n",
    "\n",
    "for channel in channels:\n",
    "    n_bins = len(fit_vois)*10\n",
    "    full_migration = np.zeros((n_bins, n_bins))\n",
    "    for i, voi in enumerate(fit_vois):\n",
    "        full_migration[i*10:(i+1)*10, i*10:(i+1)*10] = migration_matrices[channel][voi]\n",
    "    full_migrations[channel] = full_migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_distributions = {}\n",
    "\n",
    "for channel in channels:\n",
    "    mc_distributions[channel] = {}\n",
    "    for voi in fit_vois:\n",
    "        query = f\"SIG_ID in (4.1, 4.2) and {fit_range[0]} < {fit_variable} < {fit_range[1]} and daughter__bo1__cm__spextraInfo__bodecayModeID__bc__bc == {channel}\"\n",
    "        mc_distributions[channel][voi] = np.histogram(df_mc.query(query)[voi_mc[voi]], bins=bin_edges_all[voi], weights=df_mc.query(query)[\"__weight_overall__\"])[0]\n",
    "        \n",
    "        \n",
    "mc_reco_distributions = {}\n",
    "\n",
    "for channel in channels:\n",
    "    mc_reco_distributions[channel] = {}\n",
    "    for voi in fit_vois:\n",
    "        query = f\"SIG_ID in (4.1, 4.2) and {fit_range[0]} < {fit_variable} < {fit_range[1]} and daughter__bo1__cm__spextraInfo__bodecayModeID__bc__bc == {channel}\"\n",
    "        mc_reco_distributions[channel][voi] = np.histogram(df_mc.query(query)[voi], bins=bin_edges_all[voi], weights=df_mc.query(query)[\"__weight_overall__\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_mc_distributions = {}\n",
    "\n",
    "for channel in channels:\n",
    "    full_mc_distributions[channel] = np.concatenate(tuple(mc_distributions[channel][voi] for voi in fit_vois))\n",
    "    \n",
    "full_mc_reco_distributions = {}\n",
    "\n",
    "for channel in channels:\n",
    "    full_mc_reco_distributions[channel] = np.concatenate(tuple(mc_reco_distributions[channel][voi] for voi in fit_vois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "for channel in channels:\n",
    "    for voi in fit_vois:\n",
    "        migration_matrix = migration_matrices[channel][voi]\n",
    "        fig, ax = plt.subplots(dpi=130, figsize=(6.4, 4.4 / 0.8))\n",
    "        im = ax.imshow(migration_matrix, vmin=0, vmax=1, cmap=plt.get_cmap(\"Reds\"))\n",
    "\n",
    "        # We want to show all ticks...\n",
    "        bin_edges = bin_edges_all[voi]\n",
    "        ax.set_xticks(np.arange(len(bin_edges)) - 0.5)\n",
    "        ax.set_yticks(np.arange(len(bin_edges)) - 0.5)\n",
    "        # ... and label them with the respective list entries\n",
    "        ax.set_xticklabels([f\"{x:.2f}\" for x in bin_edges])\n",
    "        ax.set_yticklabels([f\"{x:.2f}\" for x in bin_edges])\n",
    "\n",
    "        ax.set_xlabel(f\"{voi_labels[voi]} Reco\")\n",
    "        ax.set_ylabel(f\"{voi_labels[voi]} MC\")\n",
    "\n",
    "        # Create colorbar\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"3%\", pad=0.05)\n",
    "        cbar = ax.figure.colorbar(im, ax=ax, cax=cax)\n",
    "        #cbar.ax.set_ylabel(\"...\", rotation=-90, va=\"center\")\n",
    "\n",
    "        # Turn spines off and create white grid.\n",
    "        for edge, spine in ax.spines.items():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "        ax.set_xticks(np.arange(migration_matrix.shape[1]+1)-.5, minor=True)\n",
    "        ax.set_yticks(np.arange(migration_matrix.shape[0]+1)-.5, minor=True)\n",
    "        ax.grid(which=\"major\", color=\"black\", linestyle='-', linewidth=1.2)\n",
    "        ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        for i in range(len(bin_edges)-1):\n",
    "            for j in range(len(bin_edges)-1):\n",
    "                text = ax.text(j, i, f\"{migration_matrix[i, j]:.3f}\",\n",
    "                               ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "\n",
    "\n",
    "        add_watermark(ax, channel_label[channel])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{plotoutdir}/migration_matrix_channel{channel}_{voi}.pdf\", transparent=True)\n",
    "        plt.savefig(f\"{plotoutdir}/migration_matrix_channel{channel}_{voi}.png\", transparent=True) \n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Apply Unfolding and Acceptance Correction\n",
    "\n",
    "Below is the background subtracted spectrum from the previous session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=130, figsize=(6.4, 4.4))\n",
    "\n",
    "for i, channel in enumerate([15, 16]):\n",
    "    \n",
    "    result = results[channel]\n",
    "    \n",
    "    ax.errorbar(\n",
    "        x=[x +(0.2*i - 0.2) for x in range(0, 20)],\n",
    "        y=unp.nominal_values(result),\n",
    "        yerr=unp.std_devs(result),\n",
    "        marker=markers[channel], ls=\"\", markeredgecolor='black', label=channel_label[channel],\n",
    "        \n",
    "    )\n",
    "    \n",
    "    histogram = full_mc_reco_distributions[channel]\n",
    "    ax.step(range(-1,21), np.array([histogram[0], *histogram, histogram[-1]]), \n",
    "            ls=\"solid\", lw=1, where=\"mid\", color=plt.gca().lines[-1].get_color())\n",
    "\n",
    "make_plot_pretty(ax, bin_edges_all)\n",
    "ax.set_ylim(0, 500)\n",
    "ax.set_ylabel(\"Background Subtracted Events\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{plotoutdir}/bs_spectrum.pdf\", transparent=True)\n",
    "plt.savefig(f\"{plotoutdir}/bs_spectrum.png\", transparent=True)   \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex. 5a) Apply the unfolding to the background subtracted yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=130, figsize=(6.4, 4.4))\n",
    "\n",
    "for i, channel in enumerate([15, 16]):\n",
    "    \n",
    "    # define inv_m (our unfolding matrix)\n",
    "    # inv_m = ...\n",
    "    \n",
    "    # unfold our background subtracted spectrum. The results are available in results[channel] for each channel\n",
    "    # result = ...\n",
    "    \n",
    "    ax.errorbar(\n",
    "        x=[x +(0.2*i - 0.2) for x in range(0, 20)],\n",
    "        y=unp.nominal_values(result),\n",
    "        yerr=unp.std_devs(result),\n",
    "        marker=markers[channel], ls=\"\", markeredgecolor='black', label=channel_label[channel],\n",
    "        \n",
    "    )\n",
    "    \n",
    "    histogram = full_mc_distributions[channel]\n",
    "    ax.step(range(-1,21), np.array([histogram[0], *histogram, histogram[-1]]), \n",
    "            ls=\"solid\", lw=1, where=\"mid\", color=plt.gca().lines[-1].get_color())\n",
    "        \n",
    "\n",
    "make_plot_pretty(ax, bin_edges_all)\n",
    "ax.set_ylim(0, 500)\n",
    "ax.set_ylabel(r\"Unfolded ($\\mathcal{M}$) Events\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{plotoutdir}/unfolded_m_spectrum.pdf\", transparent=True)\n",
    "plt.savefig(f\"{plotoutdir}/unfolded_m_spectrum.png\", transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_theory(ax, full_theory, bin_widths):\n",
    "    theory = full_theory[15] * bin_widths[\"mixed\"]\n",
    "    ax.step(range(-1,21), 1e15*np.array([theory[0], *theory[:20], theory[-1]]), \n",
    "            lw=1, ls=\"-\", where=\"mid\", color=\"black\", label=\"$B^0$ BGL Theory\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factor(channel):\n",
    "    factor = (2*N_BB.nominal_value * BR_GENERIC_MIXED.nominal_value) * tauBzero\n",
    "    return factor * np.ones(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex. 5b) Apply the unfolding *and* acceptance correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=130, figsize=(6.4, 4.4))\n",
    "\n",
    "for i, channel in enumerate(channels):\n",
    "    \n",
    "    # define inv_m (our unfolding matrix)\n",
    "    # inv_m = ...\n",
    "    \n",
    "    # unfold our background subtracted spectrum. The results are available in results[channel] for each channel\n",
    "    # result = ...\n",
    "    \n",
    "    factor = get_factor(channel) # This number translates yields to rates. The you have to divide by that number.\n",
    "    acceptance = acceptance_corrections[channel] # This is our determined acceptance function\n",
    "    \n",
    "    # divide the result by both the factor and the acceptance correction\n",
    "    # result = ...\n",
    "    \n",
    "    ax.errorbar(\n",
    "        x=[x +(0.2*i - 0.2) for x in range(0, 20)],\n",
    "        y=1e15*unp.nominal_values(result),\n",
    "        yerr=1e15*unp.std_devs(result),\n",
    "        marker=markers[channel], ls=\"\", markeredgecolor='black', label=channel_label[channel],\n",
    "    )\n",
    "\n",
    "plot_theory(ax, full_theory_bgl, bin_widths)\n",
    "make_plot_pretty(ax, bin_edges_all)\n",
    "ax.set_ylim(0, 5)\n",
    "ax.set_ylabel(r\"($\\mathcal{M}$) $\\mathrm{d} \\Gamma / \\mathrm{d}x$ $\\times 10^{-15}$ GeV$^{-1}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{plotoutdir}/acceptance_corrected_m_spectrum.pdf\", transparent=True)\n",
    "plt.savefig(f\"{plotoutdir}/acceptance_corrected_m_spectrum.png\", transparent=True)   \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything at once\n",
    "\n",
    "Here we basically re-do everything we did above, with the exception that we do it globally instead of channel by channel. This is useful to properly carry the systematic affects in the unfolding process. Conceptually this is the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_yields = yields['$\\nu_\\mathrm{sig}$'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_covariance = np.outer(\n",
    "    yields['$\\sigma_\\mathrm{tot}$'].values, yields['$\\sigma_\\mathrm{tot}$'].values\n",
    ") * pd.read_pickle(os.path.join(f\"output/Fitting/{data_type}\", f\"correlation_full.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_yields = np.array(correlated_values(full_yields, full_covariance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_m = scipy.linalg.block_diag(*[np.linalg.inv(full_migrations[channel]) for channel in channels])\n",
    "acceptance_correction = np.array([acceptance_corrections[channel] for channel in channels]).flatten()\n",
    "factor = np.array([get_factor(channel) for channel in channels]).flatten()\n",
    "bw = bin_widths[\"mixed\"]\n",
    "\n",
    "unfolded = inv_m @ fit_yields\n",
    "corrected =  np.array([r / a / f for r, a, f in zip(unfolded, acceptance_correction, factor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(plotoutdir, f\"minv_central_values_full.npy\"), unp.nominal_values(corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(plotoutdir, f\"minv_covariance_full.npy\"), uncertainties.covariance_matrix(corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
